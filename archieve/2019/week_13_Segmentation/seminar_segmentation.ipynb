{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmantation\n",
    "\n",
    "В этом занятии мы рассмотрим полный цикл подготовки модели нейронной сети для решения задачи сегментации на примере задачи [Carvana Challange](https://www.kaggle.com/c/carvana-image-masking-challenge).\n",
    "\n",
    "[Данные](https://drive.google.com/file/d/13_atfxCGnS7Qs3WYk_1h5-3RXaO5-efc/view?usp=sharing) для семинара.\n",
    "\n",
    "__В этом занятии будет:__\n",
    "\n",
    "__1. [Подготовка данных](#1.-Подготовка-данных)__\n",
    "\n",
    "__2. [Сборка модели](#2.-Сборка-модели)__\n",
    "\n",
    "__3. [Тренировка](#3.-Тренировка)__\n",
    "\n",
    "__4. [Аугментация](#4.-Аугментация)__\n",
    "\n",
    "__5. [Try Hard](#5.-Try-Hard)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import librires "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install new packages\n",
    "!pip install albumentations\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# nn modules\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Input,\n",
    "    GlobalAveragePooling2D, \n",
    "    Dropout, \n",
    "    UpSampling2D, \n",
    "    Conv2D, \n",
    "    MaxPooling2D,\n",
    "    Concatenate,\n",
    "    Activation\n",
    ")\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, UpSampling2D, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths    \n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "        \n",
    "    img = img.reshape(shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/train_masks.csv')\n",
    "print(f'Data shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train/val dataset\n",
    "all_id = np.array(range(df.shape[0]), dtype=np.uint8)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(all_id)\n",
    "\n",
    "split_size = 0.8\n",
    "train_df = df.loc[all_id[:int(df.shape[0] *split_size)]]\n",
    "val_df = df.loc[all_id[int(df.shape[0] * split_size):]]\n",
    "\n",
    "print(f'Train DataFrame shape: {train_df.shape}\\n'\n",
    "     f'Validation DataFrame shape: {val_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_num = 10\n",
    "random_id = np.random.choice(train_df.shape[0], size=ex_num, replace=False)\n",
    "\n",
    "for i, row_id in enumerate(random_id):\n",
    "    img_name, mask_rle = train_df.iloc[row_id]\n",
    "    img = cv2.imread('input/train/{}'.format(img_name))\n",
    "    w, h, _ = img.shape\n",
    "    mask = rle_decode(mask_rle, shape=(w, h, 1))\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(25, 25))\n",
    "    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # change colorspace for plt\n",
    "    axes[1].imshow(mask[..., 0], cmap='gray')\n",
    "    for ax in axes:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_generator(gen_df, batch_size=4):\n",
    "    while True:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        random_id = np.random.choice(gen_df.shape[0], size=batch_size, replace=False)\n",
    "        for row_id in random_id:\n",
    "            img_name, mask_rle = gen_df.iloc[row_id]\n",
    "            img = cv2.imread('input/train/{}'.format(img_name))\n",
    "            w, h, _ = img.shape\n",
    "            mask = rle_decode(mask_rle, shape=(w, h, 1))\n",
    "\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            mask = cv2.resize(mask, (256, 256))\n",
    "            \n",
    "            x_batch += [crop_img]\n",
    "            y_batch += [crop_mask]\n",
    "\n",
    "        x_batch = np.array(x_batch) / 255.  # normalize\n",
    "        y_batch = np.array(y_batch)\n",
    "\n",
    "        yield x_batch, np.expand_dims(y_batch, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator testing\n",
    "train_gen = keras_generator(train_df, 10)\n",
    "x, y = next(iter(train_gen))\n",
    "\n",
    "print(f'Input size: {x.shape}\\n'\n",
    "     f'Output size: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Сборка модели\n",
    "\n",
    "Начнем собирать первую модель для решения задачи сегментации на основе FCN\n",
    "<img src=\"https://i.ibb.co/TMwThH1/fcn.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = VGG16(weights='imagenet', input_shape=(256,256,3), include_top=False)\n",
    "up = UpSampling2D(32, interpolation='bilinear')(vgg16_model.output)\n",
    "conv = Conv2D(1, (1, 1))(up)\n",
    "conv = Activation('sigmoid')(conv)\n",
    "\n",
    "fcn_model = Model(input=vgg16_model.input, output=conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# посмотрим на архитекутуру сети\n",
    "fcn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# тест входных и выходных размерностей модели\n",
    "test_array = np.zeros((10, 256, 256, 3), dtype='float32')\n",
    "output = fcn_model(K.variable(test_array))\n",
    "\n",
    "assert K.eval(output).shape[:3] == test_array.shape[:3], f'Incorect output shape: {K.eval(output).shape} \\\n",
    "when input shape: {test_array.shape}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_w = keras.callbacks.ModelCheckpoint('fcn_best.h5',\n",
    "                                monitor='val_loss',\n",
    "                                verbose=0,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True,\n",
    "                                mode='auto',\n",
    "                                period=1)\n",
    "\n",
    "last_w = keras.callbacks.ModelCheckpoint('fcn_last.h5',\n",
    "                                monitor='val_loss',\n",
    "                                verbose=0,\n",
    "                                save_best_only=False,\n",
    "                                save_weights_only=True,\n",
    "                                mode='auto',\n",
    "                                period=1)\n",
    "callbacks = [best_w, last_w]\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "fcn_model.compile(adam, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Тренировка "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_gen = keras_generator(train_df, batch_size)\n",
    "val_gen = keras_generator(val_df, batch_size)\n",
    "\n",
    "hist = fcn_model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=3,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=5,\n",
    "    class_weight=None,\n",
    "    max_queue_size=10,\n",
    "    workers=6,\n",
    "    use_multiprocessing=True,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_predicts(model, ex_num=5, th_pred=0.5):\n",
    "    random_id = np.random.choice(val_df.shape[0], size=ex_num, replace=False)\n",
    "\n",
    "    for i, row_id in enumerate(random_id):\n",
    "        img_name, mask_rle = train_df.iloc[row_id]\n",
    "        img = cv2.imread('input/train/{}'.format(img_name))\n",
    "        w, h, _ = img.shape\n",
    "        true_mask = rle_decode(mask_rle, shape=(w, h, 1))\n",
    "        pred_mask = model.predict(cv2.resize(img, (256, 256)).reshape(1, 256, 256, 3)).reshape(256, 256, 1)\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25, 25))\n",
    "        axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # change colorspace for plt\n",
    "        axes[1].imshow(pred_mask[..., 0] > 0.5, cmap='gray')\n",
    "        axes[2].imshow(true_mask[..., 0], cmap='gray')\n",
    "        for ax in axes:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicts(fcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Аугментация \n",
    "\n",
    "Рассмотрим одну из популярных реализаций аугментаций ```albumentations```. Данная библиотека содержит больше базовых функций для аугментации, чем есть в ```Keras```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    CLAHE, RandomRotate90, Transpose, RandomCrop, Resize, ShiftScaleRotate, Blur, OpticalDistortion, \n",
    "    GridDistortion, HueSaturationValue, IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, \n",
    "    MedianBlur, IAAPiecewiseAffine, IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, \n",
    "    Flip, HorizontalFlip, OneOf, Compose, PadIfNeeded, LongestMaxSize, PadIfNeeded, ElasticTransform,Cutout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим функцию аугментации\n",
    "def strong_aug(p=1.0):\n",
    "    \"\"\"\n",
    "    param p: вероятность применения аугментации\n",
    "    \"\"\"\n",
    "    return Compose([\n",
    "        ShiftScaleRotate(shift_limit=0.125, scale_limit=0.2, rotate_limit=10, p=0.7, border_mode=cv2.BORDER_CONSTANT),\n",
    "        RandomCrop(256, 256),\n",
    "        #PadIfNeeded(min_height=224, min_width=224, border_mode=cv2.BORDER_CONSTANT, p=1.0),\n",
    "        #Resize(64, 64),\n",
    "        #RandomRotate90(),\n",
    "        ElasticTransform(1.), \n",
    "        #HorizontalFlip(),\n",
    "        #Cutout(p=1.),\n",
    "        #Transpose(),\n",
    "        OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=0.3),\n",
    "        OneOf([\n",
    "            MotionBlur(p=.4),\n",
    "            MedianBlur(blur_limit=3, p=0.3),\n",
    "            Blur(blur_limit=3, p=0.3),\n",
    "        ], p=0.5),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=0.1),\n",
    "            IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.5),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=3),\n",
    "            IAASharpen(),\n",
    "            IAAEmboss(),\n",
    "            RandomContrast(),\n",
    "            RandomBrightness(),\n",
    "        ], p=0.4),\n",
    "        HueSaturationValue(p=0.7),  \n",
    "    ],\n",
    "        p=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим несколько примеров применения построенной функции аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmentation = strong_aug(p=1.0)\n",
    "\n",
    "row_id = np.random.choice(val_df.shape[0], size=1, replace=False)\n",
    "img_name, mask_rle = train_df.iloc[row_id[0]]\n",
    "img = cv2.imread('input/train/{}'.format(img_name))\n",
    "w, h, _ = img.shape\n",
    "mask = rle_decode(mask_rle, shape=(w, h, 1))\n",
    "\n",
    "data = {'image': img.astype('uint8'), 'mask': mask}\n",
    "augmented = augmentation(**data)\n",
    "crop_img, crop_mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15))\n",
    "axes[0].imshow(cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB))\n",
    "axes[1].imshow(crop_mask[:,:,0], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим генератор с аугментацией и посмотрим на результат тренировки модели\n",
    "\n",
    "def keras_generator_aug(gen_df, batch_size=4):\n",
    "    while True:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        random_id = np.random.choice(gen_df.shape[0], size=batch_size, replace=False)\n",
    "        for row_id in random_id:\n",
    "            img_name, mask_rle = gen_df.iloc[row_id]\n",
    "            img = cv2.imread('input/train/{}'.format(img_name))\n",
    "            w, h, _ = img.shape\n",
    "            mask = rle_decode(mask_rle, shape=(w, h, 1))\n",
    "\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            mask = cv2.resize(mask, (256, 256))\n",
    "            \n",
    "            augmentation = strong_aug(p=1.0)\n",
    "            data = {'image': img.astype('uint8'), 'mask': mask}\n",
    "            augmented = augmentation(**data)\n",
    "            crop_img, crop_mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "            \n",
    "            x_batch += [crop_img]\n",
    "            y_batch += [crop_mask]\n",
    "\n",
    "        x_batch = np.array(x_batch) / 255.  # normalize\n",
    "        y_batch = np.array(y_batch)\n",
    "\n",
    "        yield x_batch, np.expand_dims(y_batch, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_gen = keras_generator_aug(train_df, batch_size)\n",
    "val_gen = keras_generator_aug(val_df, batch_size)\n",
    "\n",
    "hist = fcn_model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=3,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=5,\n",
    "    class_weight=None,\n",
    "    max_queue_size=10,\n",
    "    workers=6,\n",
    "    use_multiprocessing=True,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    verbose=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Try Hard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SegNet\n",
    "\n",
    "Усложним вариант модели на иерархический Upsampling. Задача - реализовать модель и посмотреть на результат. Примените аугментацию в генераторе для train.\n",
    "<img src=\"https://i.ibb.co/nL3n9Br/segnet.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanila UNet\n",
    "\n",
    "Пришло время для Unet. Задача аналогична - реализовать модель и посмотреть на результат. Примените аугментацию в генераторе для train.\n",
    "<img src=\"https://i.ibb.co/wC3FxCb/unet.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
